{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# HW 1\n",
    "## Machine Learning with Python IDS-594 \n",
    "### Due date: 6:00 pm 09/20/2019"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this homework you will do a classification task. You will build a model that predicts whether a person has heart disease or not. While doing this homework you will learn: <br> 1) how to pre-process the data <br> 2) perform model selection (which algorithm should you use for building your model, logistic regression or k-nearest neighbor?)  <br>3) perform hyperparameter selection (what value of K should you use in you k-nearest neighbor algorithm) <br>After you selected the best model via cross validation, you will apply your model to the test set and report your performance to me."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Refer to Python's documentation for each function to see the input arguments, outputs, and methods."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The inputs of this homework are heart_disease.xlsx which contains the data, and heart.doc which contains some information regarding each feature (columns in the heart_disease.xlsx file)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Fill in the cells that have \"TO DO\", and give me your output scores and answer any questions I asked in the problems in a report."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import the important packages here\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn import metrics\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Problem 1) Cleaning data and visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use pandas.read_excel to read the heart_disease.xlsx file into a dataframe called data\n",
    "data = pd.read_excel('heart_disease.xlsx')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>age</th>\n",
       "      <th>sex</th>\n",
       "      <th>chest_pain</th>\n",
       "      <th>bp</th>\n",
       "      <th>chol</th>\n",
       "      <th>blood_sugar</th>\n",
       "      <th>ecg</th>\n",
       "      <th>heart_rate</th>\n",
       "      <th>angia</th>\n",
       "      <th>oldpeak</th>\n",
       "      <th>slope</th>\n",
       "      <th>vessel_num</th>\n",
       "      <th>thal</th>\n",
       "      <th>heart_disease</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>70</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>130</td>\n",
       "      <td>322</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>109</td>\n",
       "      <td>0</td>\n",
       "      <td>2.4</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>67</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>115</td>\n",
       "      <td>564</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>160</td>\n",
       "      <td>0</td>\n",
       "      <td>1.6</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>7</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>57</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>124</td>\n",
       "      <td>261</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>141</td>\n",
       "      <td>0</td>\n",
       "      <td>0.3</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>7</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>64</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>128</td>\n",
       "      <td>263</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>105</td>\n",
       "      <td>1</td>\n",
       "      <td>0.2</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>7</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>74</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>120</td>\n",
       "      <td>269</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>121</td>\n",
       "      <td>1</td>\n",
       "      <td>0.2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   age  sex  chest_pain   bp  chol  blood_sugar  ecg  heart_rate  angia  \\\n",
       "0   70    1           4  130   322            0    2         109      0   \n",
       "1   67    0           3  115   564            0    2         160      0   \n",
       "2   57    1           2  124   261            0    0         141      0   \n",
       "3   64    1           4  128   263            0    0         105      1   \n",
       "4   74    0           2  120   269            0    2         121      1   \n",
       "\n",
       "   oldpeak  slope  vessel_num  thal  heart_disease  \n",
       "0      2.4      2           3     3              2  \n",
       "1      1.6      2           0     7              1  \n",
       "2      0.3      1           0     7              2  \n",
       "3      0.2      2           1     7              1  \n",
       "4      0.2      1           1     3              1  "
      ]
     },
     "execution_count": 101,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Look at the first 5 rows by using head(5)\n",
    "data.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>age</th>\n",
       "      <th>sex</th>\n",
       "      <th>chest_pain</th>\n",
       "      <th>bp</th>\n",
       "      <th>chol</th>\n",
       "      <th>blood_sugar</th>\n",
       "      <th>ecg</th>\n",
       "      <th>heart_rate</th>\n",
       "      <th>angia</th>\n",
       "      <th>oldpeak</th>\n",
       "      <th>slope</th>\n",
       "      <th>vessel_num</th>\n",
       "      <th>thal</th>\n",
       "      <th>heart_disease</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>270.000000</td>\n",
       "      <td>270.000000</td>\n",
       "      <td>270.000000</td>\n",
       "      <td>270.000000</td>\n",
       "      <td>270.000000</td>\n",
       "      <td>270.000000</td>\n",
       "      <td>270.000000</td>\n",
       "      <td>270.000000</td>\n",
       "      <td>270.000000</td>\n",
       "      <td>270.00000</td>\n",
       "      <td>270.000000</td>\n",
       "      <td>270.000000</td>\n",
       "      <td>270.000000</td>\n",
       "      <td>270.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>54.433333</td>\n",
       "      <td>0.677778</td>\n",
       "      <td>3.174074</td>\n",
       "      <td>131.344444</td>\n",
       "      <td>249.659259</td>\n",
       "      <td>0.148148</td>\n",
       "      <td>1.022222</td>\n",
       "      <td>149.677778</td>\n",
       "      <td>0.329630</td>\n",
       "      <td>1.05000</td>\n",
       "      <td>1.585185</td>\n",
       "      <td>0.670370</td>\n",
       "      <td>4.696296</td>\n",
       "      <td>1.444444</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>9.109067</td>\n",
       "      <td>0.468195</td>\n",
       "      <td>0.950090</td>\n",
       "      <td>17.861608</td>\n",
       "      <td>51.686237</td>\n",
       "      <td>0.355906</td>\n",
       "      <td>0.997891</td>\n",
       "      <td>23.165717</td>\n",
       "      <td>0.470952</td>\n",
       "      <td>1.14521</td>\n",
       "      <td>0.614390</td>\n",
       "      <td>0.943896</td>\n",
       "      <td>1.940659</td>\n",
       "      <td>0.497827</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>29.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>94.000000</td>\n",
       "      <td>126.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>71.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>48.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>120.000000</td>\n",
       "      <td>213.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>133.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>55.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>130.000000</td>\n",
       "      <td>245.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>153.500000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.80000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>61.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>140.000000</td>\n",
       "      <td>280.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>166.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.60000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>7.000000</td>\n",
       "      <td>2.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>77.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>200.000000</td>\n",
       "      <td>564.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>202.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>6.20000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>7.000000</td>\n",
       "      <td>2.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              age         sex  chest_pain          bp        chol  \\\n",
       "count  270.000000  270.000000  270.000000  270.000000  270.000000   \n",
       "mean    54.433333    0.677778    3.174074  131.344444  249.659259   \n",
       "std      9.109067    0.468195    0.950090   17.861608   51.686237   \n",
       "min     29.000000    0.000000    1.000000   94.000000  126.000000   \n",
       "25%     48.000000    0.000000    3.000000  120.000000  213.000000   \n",
       "50%     55.000000    1.000000    3.000000  130.000000  245.000000   \n",
       "75%     61.000000    1.000000    4.000000  140.000000  280.000000   \n",
       "max     77.000000    1.000000    4.000000  200.000000  564.000000   \n",
       "\n",
       "       blood_sugar         ecg  heart_rate       angia    oldpeak       slope  \\\n",
       "count   270.000000  270.000000  270.000000  270.000000  270.00000  270.000000   \n",
       "mean      0.148148    1.022222  149.677778    0.329630    1.05000    1.585185   \n",
       "std       0.355906    0.997891   23.165717    0.470952    1.14521    0.614390   \n",
       "min       0.000000    0.000000   71.000000    0.000000    0.00000    1.000000   \n",
       "25%       0.000000    0.000000  133.000000    0.000000    0.00000    1.000000   \n",
       "50%       0.000000    2.000000  153.500000    0.000000    0.80000    2.000000   \n",
       "75%       0.000000    2.000000  166.000000    1.000000    1.60000    2.000000   \n",
       "max       1.000000    2.000000  202.000000    1.000000    6.20000    3.000000   \n",
       "\n",
       "       vessel_num        thal  heart_disease  \n",
       "count  270.000000  270.000000     270.000000  \n",
       "mean     0.670370    4.696296       1.444444  \n",
       "std      0.943896    1.940659       0.497827  \n",
       "min      0.000000    3.000000       1.000000  \n",
       "25%      0.000000    3.000000       1.000000  \n",
       "50%      0.000000    3.000000       1.000000  \n",
       "75%      1.000000    7.000000       2.000000  \n",
       "max      3.000000    7.000000       2.000000  "
      ]
     },
     "execution_count": 102,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Get the statistics of your dataframe\n",
    "data.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "age              False\n",
       "sex              False\n",
       "chest_pain       False\n",
       "bp               False\n",
       "chol             False\n",
       "blood_sugar      False\n",
       "ecg              False\n",
       "heart_rate       False\n",
       "angia            False\n",
       "oldpeak          False\n",
       "slope            False\n",
       "vessel_num       False\n",
       "thal             False\n",
       "heart_disease    False\n",
       "dtype: bool"
      ]
     },
     "execution_count": 103,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Are there any columns that contain a missing value? If yes, substitute those with the mean value of each column!\n",
    "data.isnull().any()\n",
    "\n",
    "#None of the columns contain missing values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Text(0, 0.5, 'frequency of disease')"
      ]
     },
     "execution_count": 104,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Look at the disease Frequency for chest pain level (do this for other categorical variables to see if they are useful features)\n",
    "%matplotlib inline\n",
    "pd.crosstab(data.chest_pain,data.heart_disease).plot(kind='bar')\n",
    "plt.title('disease Frequency for chest pain level')\n",
    "plt.xlabel('chest pain level')\n",
    "plt.ylabel('frequency of disease')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Text(0, 0.5, 'frequency of disease')"
      ]
     },
     "execution_count": 105,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "%matplotlib inline\n",
    "pd.crosstab(data.ecg,data.heart_disease).plot(kind='bar')\n",
    "plt.title('disease Frequency for ecg')\n",
    "plt.xlabel('ecg')\n",
    "plt.ylabel('frequency of disease')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Text(0, 0.5, 'frequency of disease')"
      ]
     },
     "execution_count": 106,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "%matplotlib inline\n",
    "pd.crosstab(data.thal,data.heart_disease).plot(kind='bar')\n",
    "plt.title('disease Frequency for thal')\n",
    "plt.xlabel('thal')\n",
    "plt.ylabel('frequency of disease')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use pandas.get_dummies and put the column names for the categorical variables (refer to the documentation to find which columns are categorical variables). This will create a dummy variable for each level of categories.\n",
    "\n",
    "data = pd.get_dummies(data , columns = ['ecg','chest_pain','thal'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1    150\n",
       "2    120\n",
       "Name: heart_disease, dtype: int64"
      ]
     },
     "execution_count": 108,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# What is number of classes disease/not_disease?\n",
    "data['heart_disease'].value_counts()\n",
    "# Absence of heart disease - 150\n",
    "# Presence of heart disease - 120"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import seaborn as sns\n",
    "sns.countplot(x='heart_disease', data=data, palette='hls')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get your class labels in a variable called y, and remove it from your dataframe . Now, data contains your samples and features, and y contains your labels\n",
    "y = data['heart_disease']\n",
    "data.drop('heart_disease', axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(216, 20) (216,)\n",
      "(54, 20) (54,)\n"
     ]
    }
   ],
   "source": [
    "# Split the data into a train and validation set. You won't touch the test set until the very end of this program. \n",
    "# Perform any analysis (model selection, hyperparameter selection) on your training data (X_train_outer)\n",
    "# DO NOT TOUCH X_test UNTIL THE END OF THIS PROGRAM!!!!\n",
    "X_train_outer, X_test, y_train_outer, y_test = train_test_split(data, y, test_size=0.2,random_state = 23)\n",
    "print (X_train_outer.shape, y_train_outer.shape)\n",
    "print (X_test.shape, y_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Problem 2) Classification using nearest neighbor classifier, and see overfitting and underfitting by changing the value of n_neighbors (vary it from 1 to the number of samples -- len(X_train_inner)) What is the accuracy on training and validation when k=1? What about k=len(X_train_inner) ? When underfitting happens when overfitting?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(172, 20) (172,)\n",
      "(44, 20) (44,)\n"
     ]
    }
   ],
   "source": [
    "# Split X_train_outer again into X_train_inner, X_val, y_train_inner, y_val (We have an inner training set, and the validation set)\n",
    "X_train_inner, X_val, y_train_inner, y_val = train_test_split(X_train_outer, y_train_outer, test_size=0.2,random_state = 23)\n",
    "print (X_train_inner.shape, y_train_inner.shape)\n",
    "print (X_val.shape, y_val.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Standardize the training set, and then apply the transformation values to the val set\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "scaler = StandardScaler().fit(X_train_inner)\n",
    "X_train_inner_std = scaler.transform(X_train_inner)\n",
    "X_val_std  = scaler.transform(X_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy on training data for K= 1 is : 1.0\n",
      "Accuracy on validation data for K= 1 is : 0.6136363636363636\n",
      "Accuracy on training data for K= 2 is : 0.872093023255814\n",
      "Accuracy on validation data for K= 2 is : 0.6818181818181818\n",
      "Accuracy on training data for K= 3 is : 0.8837209302325582\n",
      "Accuracy on validation data for K= 3 is : 0.7045454545454546\n",
      "Accuracy on training data for K= 4 is : 0.872093023255814\n",
      "Accuracy on validation data for K= 4 is : 0.7045454545454546\n",
      "Accuracy on training data for K= 5 is : 0.877906976744186\n",
      "Accuracy on validation data for K= 5 is : 0.7272727272727273\n",
      "Accuracy on training data for K= 6 is : 0.877906976744186\n",
      "Accuracy on validation data for K= 6 is : 0.7272727272727273\n",
      "Accuracy on training data for K= 7 is : 0.8895348837209303\n",
      "Accuracy on validation data for K= 7 is : 0.7045454545454546\n",
      "Accuracy on training data for K= 8 is : 0.8895348837209303\n",
      "Accuracy on validation data for K= 8 is : 0.7045454545454546\n",
      "Accuracy on training data for K= 9 is : 0.8953488372093024\n",
      "Accuracy on validation data for K= 9 is : 0.7272727272727273\n",
      "Accuracy on training data for K= 10 is : 0.8895348837209303\n",
      "Accuracy on validation data for K= 10 is : 0.7272727272727273\n",
      "Accuracy on training data for K= 11 is : 0.8895348837209303\n",
      "Accuracy on validation data for K= 11 is : 0.7045454545454546\n",
      "Accuracy on training data for K= 12 is : 0.872093023255814\n",
      "Accuracy on validation data for K= 12 is : 0.75\n",
      "Accuracy on training data for K= 13 is : 0.8895348837209303\n",
      "Accuracy on validation data for K= 13 is : 0.7272727272727273\n",
      "Accuracy on training data for K= 14 is : 0.8895348837209303\n",
      "Accuracy on validation data for K= 14 is : 0.7272727272727273\n",
      "Accuracy on training data for K= 15 is : 0.8895348837209303\n",
      "Accuracy on validation data for K= 15 is : 0.7272727272727273\n",
      "Accuracy on training data for K= 16 is : 0.8837209302325582\n",
      "Accuracy on validation data for K= 16 is : 0.7272727272727273\n",
      "Accuracy on training data for K= 17 is : 0.8895348837209303\n",
      "Accuracy on validation data for K= 17 is : 0.7272727272727273\n",
      "Accuracy on training data for K= 18 is : 0.8837209302325582\n",
      "Accuracy on validation data for K= 18 is : 0.7272727272727273\n",
      "Accuracy on training data for K= 19 is : 0.8895348837209303\n",
      "Accuracy on validation data for K= 19 is : 0.7272727272727273\n",
      "Accuracy on training data for K= 20 is : 0.8837209302325582\n",
      "Accuracy on validation data for K= 20 is : 0.7272727272727273\n",
      "Accuracy on training data for K= 21 is : 0.8953488372093024\n",
      "Accuracy on validation data for K= 21 is : 0.7272727272727273\n",
      "Accuracy on training data for K= 22 is : 0.9011627906976745\n",
      "Accuracy on validation data for K= 22 is : 0.7272727272727273\n",
      "Accuracy on training data for K= 23 is : 0.8953488372093024\n",
      "Accuracy on validation data for K= 23 is : 0.7272727272727273\n",
      "Accuracy on training data for K= 24 is : 0.8837209302325582\n",
      "Accuracy on validation data for K= 24 is : 0.7272727272727273\n",
      "Accuracy on training data for K= 25 is : 0.8837209302325582\n",
      "Accuracy on validation data for K= 25 is : 0.7272727272727273\n",
      "Accuracy on training data for K= 26 is : 0.8895348837209303\n",
      "Accuracy on validation data for K= 26 is : 0.7272727272727273\n",
      "Accuracy on training data for K= 27 is : 0.8837209302325582\n",
      "Accuracy on validation data for K= 27 is : 0.7272727272727273\n",
      "Accuracy on training data for K= 28 is : 0.8895348837209303\n",
      "Accuracy on validation data for K= 28 is : 0.75\n",
      "Accuracy on training data for K= 29 is : 0.8953488372093024\n",
      "Accuracy on validation data for K= 29 is : 0.7272727272727273\n",
      "Accuracy on training data for K= 30 is : 0.8895348837209303\n",
      "Accuracy on validation data for K= 30 is : 0.7272727272727273\n",
      "Accuracy on training data for K= 31 is : 0.8953488372093024\n",
      "Accuracy on validation data for K= 31 is : 0.7272727272727273\n",
      "Accuracy on training data for K= 32 is : 0.9011627906976745\n",
      "Accuracy on validation data for K= 32 is : 0.7272727272727273\n",
      "Accuracy on training data for K= 33 is : 0.8895348837209303\n",
      "Accuracy on validation data for K= 33 is : 0.7272727272727273\n",
      "Accuracy on training data for K= 34 is : 0.8895348837209303\n",
      "Accuracy on validation data for K= 34 is : 0.7272727272727273\n",
      "Accuracy on training data for K= 35 is : 0.8953488372093024\n",
      "Accuracy on validation data for K= 35 is : 0.7272727272727273\n",
      "Accuracy on training data for K= 36 is : 0.8953488372093024\n",
      "Accuracy on validation data for K= 36 is : 0.7272727272727273\n",
      "Accuracy on training data for K= 37 is : 0.8953488372093024\n",
      "Accuracy on validation data for K= 37 is : 0.7272727272727273\n",
      "Accuracy on training data for K= 38 is : 0.8953488372093024\n",
      "Accuracy on validation data for K= 38 is : 0.7272727272727273\n",
      "Accuracy on training data for K= 39 is : 0.8895348837209303\n",
      "Accuracy on validation data for K= 39 is : 0.7272727272727273\n",
      "Accuracy on training data for K= 40 is : 0.8895348837209303\n",
      "Accuracy on validation data for K= 40 is : 0.7272727272727273\n",
      "Accuracy on training data for K= 41 is : 0.8895348837209303\n",
      "Accuracy on validation data for K= 41 is : 0.7272727272727273\n",
      "Accuracy on training data for K= 42 is : 0.8837209302325582\n",
      "Accuracy on validation data for K= 42 is : 0.7272727272727273\n",
      "Accuracy on training data for K= 43 is : 0.8837209302325582\n",
      "Accuracy on validation data for K= 43 is : 0.7272727272727273\n",
      "Accuracy on training data for K= 44 is : 0.8837209302325582\n",
      "Accuracy on validation data for K= 44 is : 0.7272727272727273\n",
      "Accuracy on training data for K= 45 is : 0.8895348837209303\n",
      "Accuracy on validation data for K= 45 is : 0.7272727272727273\n",
      "Accuracy on training data for K= 46 is : 0.8895348837209303\n",
      "Accuracy on validation data for K= 46 is : 0.75\n",
      "Accuracy on training data for K= 47 is : 0.8837209302325582\n",
      "Accuracy on validation data for K= 47 is : 0.75\n",
      "Accuracy on training data for K= 48 is : 0.8837209302325582\n",
      "Accuracy on validation data for K= 48 is : 0.7727272727272727\n",
      "Accuracy on training data for K= 49 is : 0.8837209302325582\n",
      "Accuracy on validation data for K= 49 is : 0.75\n",
      "Accuracy on training data for K= 50 is : 0.877906976744186\n",
      "Accuracy on validation data for K= 50 is : 0.75\n",
      "Accuracy on training data for K= 51 is : 0.877906976744186\n",
      "Accuracy on validation data for K= 51 is : 0.75\n",
      "Accuracy on training data for K= 52 is : 0.8837209302325582\n",
      "Accuracy on validation data for K= 52 is : 0.7727272727272727\n",
      "Accuracy on training data for K= 53 is : 0.8837209302325582\n",
      "Accuracy on validation data for K= 53 is : 0.7727272727272727\n",
      "Accuracy on training data for K= 54 is : 0.8895348837209303\n",
      "Accuracy on validation data for K= 54 is : 0.7727272727272727\n",
      "Accuracy on training data for K= 55 is : 0.8895348837209303\n",
      "Accuracy on validation data for K= 55 is : 0.75\n",
      "Accuracy on training data for K= 56 is : 0.877906976744186\n",
      "Accuracy on validation data for K= 56 is : 0.7727272727272727\n",
      "Accuracy on training data for K= 57 is : 0.8837209302325582\n",
      "Accuracy on validation data for K= 57 is : 0.75\n",
      "Accuracy on training data for K= 58 is : 0.877906976744186\n",
      "Accuracy on validation data for K= 58 is : 0.7727272727272727\n",
      "Accuracy on training data for K= 59 is : 0.872093023255814\n",
      "Accuracy on validation data for K= 59 is : 0.7727272727272727\n",
      "Accuracy on training data for K= 60 is : 0.877906976744186\n",
      "Accuracy on validation data for K= 60 is : 0.7727272727272727\n",
      "Accuracy on training data for K= 61 is : 0.872093023255814\n",
      "Accuracy on validation data for K= 61 is : 0.7727272727272727\n",
      "Accuracy on training data for K= 62 is : 0.8662790697674418\n",
      "Accuracy on validation data for K= 62 is : 0.7727272727272727\n",
      "Accuracy on training data for K= 63 is : 0.8662790697674418\n",
      "Accuracy on validation data for K= 63 is : 0.7727272727272727\n",
      "Accuracy on training data for K= 64 is : 0.8662790697674418\n",
      "Accuracy on validation data for K= 64 is : 0.7727272727272727\n",
      "Accuracy on training data for K= 65 is : 0.8662790697674418\n",
      "Accuracy on validation data for K= 65 is : 0.7727272727272727\n",
      "Accuracy on training data for K= 66 is : 0.8662790697674418\n",
      "Accuracy on validation data for K= 66 is : 0.7727272727272727\n",
      "Accuracy on training data for K= 67 is : 0.872093023255814\n",
      "Accuracy on validation data for K= 67 is : 0.7727272727272727\n",
      "Accuracy on training data for K= 68 is : 0.877906976744186\n",
      "Accuracy on validation data for K= 68 is : 0.7727272727272727\n",
      "Accuracy on training data for K= 69 is : 0.872093023255814\n",
      "Accuracy on validation data for K= 69 is : 0.7727272727272727\n",
      "Accuracy on training data for K= 70 is : 0.872093023255814\n",
      "Accuracy on validation data for K= 70 is : 0.7727272727272727\n",
      "Accuracy on training data for K= 71 is : 0.872093023255814\n",
      "Accuracy on validation data for K= 71 is : 0.7727272727272727\n",
      "Accuracy on training data for K= 72 is : 0.877906976744186\n",
      "Accuracy on validation data for K= 72 is : 0.7954545454545454\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy on training data for K= 73 is : 0.872093023255814\n",
      "Accuracy on validation data for K= 73 is : 0.7954545454545454\n",
      "Accuracy on training data for K= 74 is : 0.877906976744186\n",
      "Accuracy on validation data for K= 74 is : 0.7954545454545454\n",
      "Accuracy on training data for K= 75 is : 0.872093023255814\n",
      "Accuracy on validation data for K= 75 is : 0.7954545454545454\n",
      "Accuracy on training data for K= 76 is : 0.872093023255814\n",
      "Accuracy on validation data for K= 76 is : 0.7954545454545454\n",
      "Accuracy on training data for K= 77 is : 0.877906976744186\n",
      "Accuracy on validation data for K= 77 is : 0.7954545454545454\n",
      "Accuracy on training data for K= 78 is : 0.877906976744186\n",
      "Accuracy on validation data for K= 78 is : 0.7954545454545454\n",
      "Accuracy on training data for K= 79 is : 0.877906976744186\n",
      "Accuracy on validation data for K= 79 is : 0.7954545454545454\n",
      "Accuracy on training data for K= 80 is : 0.8837209302325582\n",
      "Accuracy on validation data for K= 80 is : 0.7954545454545454\n",
      "Accuracy on training data for K= 81 is : 0.8837209302325582\n",
      "Accuracy on validation data for K= 81 is : 0.7954545454545454\n",
      "Accuracy on training data for K= 82 is : 0.8895348837209303\n",
      "Accuracy on validation data for K= 82 is : 0.7954545454545454\n",
      "Accuracy on training data for K= 83 is : 0.8895348837209303\n",
      "Accuracy on validation data for K= 83 is : 0.7954545454545454\n",
      "Accuracy on training data for K= 84 is : 0.8895348837209303\n",
      "Accuracy on validation data for K= 84 is : 0.8181818181818182\n",
      "Accuracy on training data for K= 85 is : 0.8895348837209303\n",
      "Accuracy on validation data for K= 85 is : 0.7954545454545454\n",
      "Accuracy on training data for K= 86 is : 0.872093023255814\n",
      "Accuracy on validation data for K= 86 is : 0.8181818181818182\n",
      "Accuracy on training data for K= 87 is : 0.877906976744186\n",
      "Accuracy on validation data for K= 87 is : 0.7954545454545454\n",
      "Accuracy on training data for K= 88 is : 0.872093023255814\n",
      "Accuracy on validation data for K= 88 is : 0.7954545454545454\n",
      "Accuracy on training data for K= 89 is : 0.8837209302325582\n",
      "Accuracy on validation data for K= 89 is : 0.7954545454545454\n",
      "Accuracy on training data for K= 90 is : 0.877906976744186\n",
      "Accuracy on validation data for K= 90 is : 0.7954545454545454\n",
      "Accuracy on training data for K= 91 is : 0.877906976744186\n",
      "Accuracy on validation data for K= 91 is : 0.7954545454545454\n",
      "Accuracy on training data for K= 92 is : 0.8662790697674418\n",
      "Accuracy on validation data for K= 92 is : 0.8181818181818182\n",
      "Accuracy on training data for K= 93 is : 0.8662790697674418\n",
      "Accuracy on validation data for K= 93 is : 0.7954545454545454\n",
      "Accuracy on training data for K= 94 is : 0.8604651162790697\n",
      "Accuracy on validation data for K= 94 is : 0.7727272727272727\n",
      "Accuracy on training data for K= 95 is : 0.8604651162790697\n",
      "Accuracy on validation data for K= 95 is : 0.75\n",
      "Accuracy on training data for K= 96 is : 0.8604651162790697\n",
      "Accuracy on validation data for K= 96 is : 0.75\n",
      "Accuracy on training data for K= 97 is : 0.872093023255814\n",
      "Accuracy on validation data for K= 97 is : 0.75\n",
      "Accuracy on training data for K= 98 is : 0.8662790697674418\n",
      "Accuracy on validation data for K= 98 is : 0.75\n",
      "Accuracy on training data for K= 99 is : 0.8662790697674418\n",
      "Accuracy on validation data for K= 99 is : 0.7727272727272727\n",
      "Accuracy on training data for K= 100 is : 0.8546511627906976\n",
      "Accuracy on validation data for K= 100 is : 0.7727272727272727\n",
      "Accuracy on training data for K= 101 is : 0.8662790697674418\n",
      "Accuracy on validation data for K= 101 is : 0.7727272727272727\n",
      "Accuracy on training data for K= 102 is : 0.8546511627906976\n",
      "Accuracy on validation data for K= 102 is : 0.7727272727272727\n",
      "Accuracy on training data for K= 103 is : 0.8604651162790697\n",
      "Accuracy on validation data for K= 103 is : 0.7727272727272727\n",
      "Accuracy on training data for K= 104 is : 0.8604651162790697\n",
      "Accuracy on validation data for K= 104 is : 0.7727272727272727\n",
      "Accuracy on training data for K= 105 is : 0.8662790697674418\n",
      "Accuracy on validation data for K= 105 is : 0.75\n",
      "Accuracy on training data for K= 106 is : 0.8546511627906976\n",
      "Accuracy on validation data for K= 106 is : 0.7727272727272727\n",
      "Accuracy on training data for K= 107 is : 0.8604651162790697\n",
      "Accuracy on validation data for K= 107 is : 0.7727272727272727\n",
      "Accuracy on training data for K= 108 is : 0.8372093023255814\n",
      "Accuracy on validation data for K= 108 is : 0.7727272727272727\n",
      "Accuracy on training data for K= 109 is : 0.8546511627906976\n",
      "Accuracy on validation data for K= 109 is : 0.75\n",
      "Accuracy on training data for K= 110 is : 0.8255813953488372\n",
      "Accuracy on validation data for K= 110 is : 0.7727272727272727\n",
      "Accuracy on training data for K= 111 is : 0.8372093023255814\n",
      "Accuracy on validation data for K= 111 is : 0.75\n",
      "Accuracy on training data for K= 112 is : 0.8081395348837209\n",
      "Accuracy on validation data for K= 112 is : 0.7727272727272727\n",
      "Accuracy on training data for K= 113 is : 0.8081395348837209\n",
      "Accuracy on validation data for K= 113 is : 0.7272727272727273\n",
      "Accuracy on training data for K= 114 is : 0.8081395348837209\n",
      "Accuracy on validation data for K= 114 is : 0.7727272727272727\n",
      "Accuracy on training data for K= 115 is : 0.813953488372093\n",
      "Accuracy on validation data for K= 115 is : 0.7727272727272727\n",
      "Accuracy on training data for K= 116 is : 0.8081395348837209\n",
      "Accuracy on validation data for K= 116 is : 0.7727272727272727\n",
      "Accuracy on training data for K= 117 is : 0.8081395348837209\n",
      "Accuracy on validation data for K= 117 is : 0.7727272727272727\n",
      "Accuracy on training data for K= 118 is : 0.8023255813953488\n",
      "Accuracy on validation data for K= 118 is : 0.7727272727272727\n",
      "Accuracy on training data for K= 119 is : 0.8081395348837209\n",
      "Accuracy on validation data for K= 119 is : 0.7727272727272727\n",
      "Accuracy on training data for K= 120 is : 0.8081395348837209\n",
      "Accuracy on validation data for K= 120 is : 0.75\n",
      "Accuracy on training data for K= 121 is : 0.8081395348837209\n",
      "Accuracy on validation data for K= 121 is : 0.7727272727272727\n",
      "Accuracy on training data for K= 122 is : 0.8081395348837209\n",
      "Accuracy on validation data for K= 122 is : 0.75\n",
      "Accuracy on training data for K= 123 is : 0.8081395348837209\n",
      "Accuracy on validation data for K= 123 is : 0.75\n",
      "Accuracy on training data for K= 124 is : 0.8023255813953488\n",
      "Accuracy on validation data for K= 124 is : 0.7727272727272727\n",
      "Accuracy on training data for K= 125 is : 0.8023255813953488\n",
      "Accuracy on validation data for K= 125 is : 0.7727272727272727\n",
      "Accuracy on training data for K= 126 is : 0.7965116279069767\n",
      "Accuracy on validation data for K= 126 is : 0.7727272727272727\n",
      "Accuracy on training data for K= 127 is : 0.8023255813953488\n",
      "Accuracy on validation data for K= 127 is : 0.7727272727272727\n",
      "Accuracy on training data for K= 128 is : 0.7906976744186046\n",
      "Accuracy on validation data for K= 128 is : 0.7727272727272727\n",
      "Accuracy on training data for K= 129 is : 0.7906976744186046\n",
      "Accuracy on validation data for K= 129 is : 0.7727272727272727\n",
      "Accuracy on training data for K= 130 is : 0.7732558139534884\n",
      "Accuracy on validation data for K= 130 is : 0.7727272727272727\n",
      "Accuracy on training data for K= 131 is : 0.7790697674418605\n",
      "Accuracy on validation data for K= 131 is : 0.7727272727272727\n",
      "Accuracy on training data for K= 132 is : 0.7674418604651163\n",
      "Accuracy on validation data for K= 132 is : 0.7727272727272727\n",
      "Accuracy on training data for K= 133 is : 0.7674418604651163\n",
      "Accuracy on validation data for K= 133 is : 0.7727272727272727\n",
      "Accuracy on training data for K= 134 is : 0.7616279069767442\n",
      "Accuracy on validation data for K= 134 is : 0.75\n",
      "Accuracy on training data for K= 135 is : 0.7732558139534884\n",
      "Accuracy on validation data for K= 135 is : 0.7727272727272727\n",
      "Accuracy on training data for K= 136 is : 0.7383720930232558\n",
      "Accuracy on validation data for K= 136 is : 0.75\n",
      "Accuracy on training data for K= 137 is : 0.75\n",
      "Accuracy on validation data for K= 137 is : 0.75\n",
      "Accuracy on training data for K= 138 is : 0.7093023255813954\n",
      "Accuracy on validation data for K= 138 is : 0.7272727272727273\n",
      "Accuracy on training data for K= 139 is : 0.7209302325581395\n",
      "Accuracy on validation data for K= 139 is : 0.7272727272727273\n",
      "Accuracy on training data for K= 140 is : 0.6802325581395349\n",
      "Accuracy on validation data for K= 140 is : 0.7272727272727273\n",
      "Accuracy on training data for K= 141 is : 0.686046511627907\n",
      "Accuracy on validation data for K= 141 is : 0.7272727272727273\n",
      "Accuracy on training data for K= 142 is : 0.6744186046511628\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy on validation data for K= 142 is : 0.7045454545454546\n",
      "Accuracy on training data for K= 143 is : 0.686046511627907\n",
      "Accuracy on validation data for K= 143 is : 0.7045454545454546\n",
      "Accuracy on training data for K= 144 is : 0.6511627906976745\n",
      "Accuracy on validation data for K= 144 is : 0.6818181818181818\n",
      "Accuracy on training data for K= 145 is : 0.6627906976744186\n",
      "Accuracy on validation data for K= 145 is : 0.7045454545454546\n",
      "Accuracy on training data for K= 146 is : 0.6337209302325582\n",
      "Accuracy on validation data for K= 146 is : 0.6818181818181818\n",
      "Accuracy on training data for K= 147 is : 0.6337209302325582\n",
      "Accuracy on validation data for K= 147 is : 0.6818181818181818\n",
      "Accuracy on training data for K= 148 is : 0.5930232558139535\n",
      "Accuracy on validation data for K= 148 is : 0.6590909090909091\n",
      "Accuracy on training data for K= 149 is : 0.5988372093023255\n",
      "Accuracy on validation data for K= 149 is : 0.6590909090909091\n",
      "Accuracy on training data for K= 150 is : 0.5581395348837209\n",
      "Accuracy on validation data for K= 150 is : 0.6136363636363636\n",
      "Accuracy on training data for K= 151 is : 0.5581395348837209\n",
      "Accuracy on validation data for K= 151 is : 0.6136363636363636\n",
      "Accuracy on training data for K= 152 is : 0.5523255813953488\n",
      "Accuracy on validation data for K= 152 is : 0.5909090909090909\n",
      "Accuracy on training data for K= 153 is : 0.5523255813953488\n",
      "Accuracy on validation data for K= 153 is : 0.5909090909090909\n",
      "Accuracy on training data for K= 154 is : 0.5523255813953488\n",
      "Accuracy on validation data for K= 154 is : 0.5909090909090909\n",
      "Accuracy on training data for K= 155 is : 0.5523255813953488\n",
      "Accuracy on validation data for K= 155 is : 0.5909090909090909\n",
      "Accuracy on training data for K= 156 is : 0.5523255813953488\n",
      "Accuracy on validation data for K= 156 is : 0.5909090909090909\n",
      "Accuracy on training data for K= 157 is : 0.5523255813953488\n",
      "Accuracy on validation data for K= 157 is : 0.5909090909090909\n",
      "Accuracy on training data for K= 158 is : 0.5523255813953488\n",
      "Accuracy on validation data for K= 158 is : 0.5909090909090909\n",
      "Accuracy on training data for K= 159 is : 0.5523255813953488\n",
      "Accuracy on validation data for K= 159 is : 0.5909090909090909\n",
      "Accuracy on training data for K= 160 is : 0.5523255813953488\n",
      "Accuracy on validation data for K= 160 is : 0.5909090909090909\n",
      "Accuracy on training data for K= 161 is : 0.5523255813953488\n",
      "Accuracy on validation data for K= 161 is : 0.5909090909090909\n",
      "Accuracy on training data for K= 162 is : 0.5523255813953488\n",
      "Accuracy on validation data for K= 162 is : 0.5909090909090909\n",
      "Accuracy on training data for K= 163 is : 0.5523255813953488\n",
      "Accuracy on validation data for K= 163 is : 0.5909090909090909\n",
      "Accuracy on training data for K= 164 is : 0.5523255813953488\n",
      "Accuracy on validation data for K= 164 is : 0.5909090909090909\n",
      "Accuracy on training data for K= 165 is : 0.5523255813953488\n",
      "Accuracy on validation data for K= 165 is : 0.5909090909090909\n",
      "Accuracy on training data for K= 166 is : 0.5523255813953488\n",
      "Accuracy on validation data for K= 166 is : 0.5909090909090909\n",
      "Accuracy on training data for K= 167 is : 0.5523255813953488\n",
      "Accuracy on validation data for K= 167 is : 0.5909090909090909\n",
      "Accuracy on training data for K= 168 is : 0.5523255813953488\n",
      "Accuracy on validation data for K= 168 is : 0.5909090909090909\n",
      "Accuracy on training data for K= 169 is : 0.5523255813953488\n",
      "Accuracy on validation data for K= 169 is : 0.5909090909090909\n",
      "Accuracy on training data for K= 170 is : 0.5523255813953488\n",
      "Accuracy on validation data for K= 170 is : 0.5909090909090909\n",
      "Accuracy on training data for K= 171 is : 0.5523255813953488\n",
      "Accuracy on validation data for K= 171 is : 0.5909090909090909\n",
      "Accuracy on training data for K= 172 is : 0.5523255813953488\n",
      "Accuracy on validation data for K= 172 is : 0.5909090909090909\n"
     ]
    }
   ],
   "source": [
    "# Fit a K-nearest neighbor classifier model to X_train_inner_std data --> Change the value of n_neighbors here and report the accuracies you get\n",
    "K_values = np.arange(0,len(X_train_inner))\n",
    "\n",
    "accuracy_training = np.array([])\n",
    "accuracy_validation = np.array([])\n",
    "\n",
    "for k in range(len(K_values)):\n",
    "    neigh = KNeighborsClassifier(n_neighbors=k+1)\n",
    "    neigh.fit(X_train_inner_std, y_train_inner)\n",
    "    \n",
    "    X_train_inner_std_pred = neigh.predict(X_train_inner_std)\n",
    "    acc_train = accuracy_score(y_train_inner, X_train_inner_std_pred)\n",
    "    accuracy_training = np.append(accuracy_training,acc_train)\n",
    "    print('Accuracy on training data for K= {} is : {}'.format(k+1,acc_train))\n",
    "    \n",
    "    X_val_std_pred = neigh.predict(X_val_std)\n",
    "    acc_val = accuracy_score(y_val, X_val_std_pred)\n",
    "    accuracy_validation = np.append(accuracy_validation,acc_val)\n",
    "    print('Accuracy on validation data for K= {} is : {}'.format(k+1,acc_val))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy on validation data is : [0.61363636 0.68181818 0.70454545 0.70454545 0.72727273 0.72727273\n",
      " 0.70454545 0.70454545 0.72727273 0.72727273 0.70454545 0.75\n",
      " 0.72727273 0.72727273 0.72727273 0.72727273 0.72727273 0.72727273\n",
      " 0.72727273 0.72727273 0.72727273 0.72727273 0.72727273 0.72727273\n",
      " 0.72727273 0.72727273 0.72727273 0.75       0.72727273 0.72727273\n",
      " 0.72727273 0.72727273 0.72727273 0.72727273 0.72727273 0.72727273\n",
      " 0.72727273 0.72727273 0.72727273 0.72727273 0.72727273 0.72727273\n",
      " 0.72727273 0.72727273 0.72727273 0.75       0.75       0.77272727\n",
      " 0.75       0.75       0.75       0.77272727 0.77272727 0.77272727\n",
      " 0.75       0.77272727 0.75       0.77272727 0.77272727 0.77272727\n",
      " 0.77272727 0.77272727 0.77272727 0.77272727 0.77272727 0.77272727\n",
      " 0.77272727 0.77272727 0.77272727 0.77272727 0.77272727 0.79545455\n",
      " 0.79545455 0.79545455 0.79545455 0.79545455 0.79545455 0.79545455\n",
      " 0.79545455 0.79545455 0.79545455 0.79545455 0.79545455 0.81818182\n",
      " 0.79545455 0.81818182 0.79545455 0.79545455 0.79545455 0.79545455\n",
      " 0.79545455 0.81818182 0.79545455 0.77272727 0.75       0.75\n",
      " 0.75       0.75       0.77272727 0.77272727 0.77272727 0.77272727\n",
      " 0.77272727 0.77272727 0.75       0.77272727 0.77272727 0.77272727\n",
      " 0.75       0.77272727 0.75       0.77272727 0.72727273 0.77272727\n",
      " 0.77272727 0.77272727 0.77272727 0.77272727 0.77272727 0.75\n",
      " 0.77272727 0.75       0.75       0.77272727 0.77272727 0.77272727\n",
      " 0.77272727 0.77272727 0.77272727 0.77272727 0.77272727 0.77272727\n",
      " 0.77272727 0.75       0.77272727 0.75       0.75       0.72727273\n",
      " 0.72727273 0.72727273 0.72727273 0.70454545 0.70454545 0.68181818\n",
      " 0.70454545 0.68181818 0.68181818 0.65909091 0.65909091 0.61363636\n",
      " 0.61363636 0.59090909 0.59090909 0.59090909 0.59090909 0.59090909\n",
      " 0.59090909 0.59090909 0.59090909 0.59090909 0.59090909 0.59090909\n",
      " 0.59090909 0.59090909 0.59090909 0.59090909 0.59090909 0.59090909\n",
      " 0.59090909 0.59090909 0.59090909 0.59090909]\n"
     ]
    }
   ],
   "source": [
    "# Print accuracy on your validation data (X_val_std)\n",
    "print('Accuracy on validation data is : {}'.format(accuracy_validation))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy on training data is : [1.         0.87209302 0.88372093 0.87209302 0.87790698 0.87790698\n",
      " 0.88953488 0.88953488 0.89534884 0.88953488 0.88953488 0.87209302\n",
      " 0.88953488 0.88953488 0.88953488 0.88372093 0.88953488 0.88372093\n",
      " 0.88953488 0.88372093 0.89534884 0.90116279 0.89534884 0.88372093\n",
      " 0.88372093 0.88953488 0.88372093 0.88953488 0.89534884 0.88953488\n",
      " 0.89534884 0.90116279 0.88953488 0.88953488 0.89534884 0.89534884\n",
      " 0.89534884 0.89534884 0.88953488 0.88953488 0.88953488 0.88372093\n",
      " 0.88372093 0.88372093 0.88953488 0.88953488 0.88372093 0.88372093\n",
      " 0.88372093 0.87790698 0.87790698 0.88372093 0.88372093 0.88953488\n",
      " 0.88953488 0.87790698 0.88372093 0.87790698 0.87209302 0.87790698\n",
      " 0.87209302 0.86627907 0.86627907 0.86627907 0.86627907 0.86627907\n",
      " 0.87209302 0.87790698 0.87209302 0.87209302 0.87209302 0.87790698\n",
      " 0.87209302 0.87790698 0.87209302 0.87209302 0.87790698 0.87790698\n",
      " 0.87790698 0.88372093 0.88372093 0.88953488 0.88953488 0.88953488\n",
      " 0.88953488 0.87209302 0.87790698 0.87209302 0.88372093 0.87790698\n",
      " 0.87790698 0.86627907 0.86627907 0.86046512 0.86046512 0.86046512\n",
      " 0.87209302 0.86627907 0.86627907 0.85465116 0.86627907 0.85465116\n",
      " 0.86046512 0.86046512 0.86627907 0.85465116 0.86046512 0.8372093\n",
      " 0.85465116 0.8255814  0.8372093  0.80813953 0.80813953 0.80813953\n",
      " 0.81395349 0.80813953 0.80813953 0.80232558 0.80813953 0.80813953\n",
      " 0.80813953 0.80813953 0.80813953 0.80232558 0.80232558 0.79651163\n",
      " 0.80232558 0.79069767 0.79069767 0.77325581 0.77906977 0.76744186\n",
      " 0.76744186 0.76162791 0.77325581 0.73837209 0.75       0.70930233\n",
      " 0.72093023 0.68023256 0.68604651 0.6744186  0.68604651 0.65116279\n",
      " 0.6627907  0.63372093 0.63372093 0.59302326 0.59883721 0.55813953\n",
      " 0.55813953 0.55232558 0.55232558 0.55232558 0.55232558 0.55232558\n",
      " 0.55232558 0.55232558 0.55232558 0.55232558 0.55232558 0.55232558\n",
      " 0.55232558 0.55232558 0.55232558 0.55232558 0.55232558 0.55232558\n",
      " 0.55232558 0.55232558 0.55232558 0.55232558]\n"
     ]
    }
   ],
   "source": [
    "# Print accuracy on your training data (X_train_inner_std)\n",
    "print('Accuracy on training data is : {}'.format(accuracy_training))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Problem 3) So, how to find best k? Perform 10-fold Cross-validation on your train set to find the best value of k for nearest neighbor classifier (you can also find it by trying different values on the hold-out set you defined above, but since the dataset is small, it is better to perform 10-fold cross-validation, why? because you may by chance get a hold-out validation set that works well with k=1! you never know! So, do it on 10 different val sets and average them to make sure you got a good k!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [],
   "source": [
    "# In each fold of your cross validation, your training fold needs to be first standardized (scaled), then an algorithm be fit\n",
    "# Then the same transformation will be applied to each validation fold\n",
    "# This is done by pipeline and is extremely useful when you use GridSearchCV or cross_val_score and etc..\n",
    "from sklearn.pipeline import Pipeline\n",
    "\n",
    "scaler = StandardScaler()\n",
    "clf = KNeighborsClassifier()\n",
    "pipeline = Pipeline([('transformer', scaler), ('estimator', clf)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [],
   "source": [
    "# param_candidate defines the set of hyperparameters that you want your function to analyze\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "param_candidate = [{'estimator__n_neighbors': np.arange(1, 100)}]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\prath\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_search.py:813: DeprecationWarning: The default of the `iid` parameter will change from True to False in version 0.22 and will be removed in 0.24. This will change numeric results when test-set sizes are unequal.\n",
      "  DeprecationWarning)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=10, error_score='raise-deprecating',\n",
       "             estimator=Pipeline(memory=None,\n",
       "                                steps=[('transformer',\n",
       "                                        StandardScaler(copy=True,\n",
       "                                                       with_mean=True,\n",
       "                                                       with_std=True)),\n",
       "                                       ('estimator',\n",
       "                                        KNeighborsClassifier(algorithm='auto',\n",
       "                                                             leaf_size=30,\n",
       "                                                             metric='minkowski',\n",
       "                                                             metric_params=None,\n",
       "                                                             n_jobs=None,\n",
       "                                                             n_neighbors=5, p=2,\n",
       "                                                             weights='uniform'))],\n",
       "                                verbose=False),\n",
       "             iid='warn', n_jobs=None,\n",
       "             param_grid=[{'estimator__n_neighbors': array([ 1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15, 16, 17,\n",
       "       18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34,\n",
       "       35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51,\n",
       "       52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67, 68,\n",
       "       69, 70, 71, 72, 73, 74, 75, 76, 77, 78, 79, 80, 81, 82, 83, 84, 85,\n",
       "       86, 87, 88, 89, 90, 91, 92, 93, 94, 95, 96, 97, 98, 99])}],\n",
       "             pre_dispatch='2*n_jobs', refit=True, return_train_score=False,\n",
       "             scoring=None, verbose=0)"
      ]
     },
     "execution_count": 119,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create a classifier object with GridSearchCV and param_candidate and fit the GridSearchCV object with X_train_outer, and y_train_outer \n",
    "# Read Python's documentation if anything is unclear!\n",
    "clf = GridSearchCV(pipeline, param_grid=param_candidate, cv=10)\n",
    "clf.fit(X_train_outer,y_train_outer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best score for data1: 0.8611111111111112\n"
     ]
    }
   ],
   "source": [
    "# print clf.best_score_ (refer to Python's documentation for the attributes of clf)\n",
    "print('Best score for data1:', clf.best_score_) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best k: {'estimator__n_neighbors': 28}\n"
     ]
    }
   ],
   "source": [
    "# View the best parameters for the model found using grid search\n",
    "print('Best k:',clf.best_params_) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Problem 4) Perform logistic regression with the default value of C=1, and obtain the cross-validation performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Do standardization before classification using Pipeline as Problem 3. You don't need any param_candidate in this case.\n",
    "pipeline1 = Pipeline([('transformer', StandardScaler()), ('estimator', LogisticRegression(multi_class=\"ovr\",C=1.0))])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\prath\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "C:\\Users\\prath\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "C:\\Users\\prath\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "C:\\Users\\prath\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "C:\\Users\\prath\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "C:\\Users\\prath\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "C:\\Users\\prath\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "C:\\Users\\prath\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "C:\\Users\\prath\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "C:\\Users\\prath\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n"
     ]
    }
   ],
   "source": [
    "# Use the cross_val_score on logistic regression on X_train_outer and y_train_outer with cv=10 and get scores\n",
    "from sklearn.model_selection import cross_val_score\n",
    "scores = cross_val_score(pipeline1,X_train_outer,y_train_outer,cv=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8516374929418408"
      ]
     },
     "execution_count": 124,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scores.mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Problem 5) Cross-validation performance of which algorithm was better? K-nearest neighbor or logistic regression? You will pick the one that gave you the highest performance (accuracy), and train your model using all training data, test it on your test set (which you never touched up until this point), get your performance, and report it (to me, to the doctor, or the hospital as the generalization performance of your model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Standardize the training set (X_train_outer), and then apply the transformation values to the test set (X_test)\n",
    "# TO DO\n",
    "scaler = StandardScaler().fit(X_train_outer)\n",
    "X_train_outer_std = scaler.transform(X_train_outer)\n",
    "X_test_std = scaler.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "KNeighborsClassifier(algorithm='auto', leaf_size=30, metric='minkowski',\n",
       "                     metric_params=None, n_jobs=None, n_neighbors=28, p=2,\n",
       "                     weights='uniform')"
      ]
     },
     "execution_count": 126,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Fit the best algorithm to X_train_outer_std, y_train_outer\n",
    "clf = KNeighborsClassifier(n_neighbors=28)\n",
    "clf.fit(X_train_outer_std, y_train_outer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8148148148148148"
      ]
     },
     "execution_count": 127,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Test on your test set X_test_std, and report accuracy_score\n",
    "X_test_std_pred = clf.predict(X_test_std)\n",
    "accuracy_score(X_test_std_pred,y_test)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
